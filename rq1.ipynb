{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "582d4d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/vittunyuta-m/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vittunyuta-m/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/vittunyuta-m/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re, csv\n",
    "\n",
    "arrange_pull_request_path = \"/mnt/ext-hdd1/pull_request_npm_asia_2020/asia_arrange_pull_request_data\" #updated 220301\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1752cc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention, blocked, blocker, break, breaking, broken, change, confusing, critical, denied, density, difficult, difficulty, effort, exclamation, failed, failing, followup, hard, high, hold, important, incompatible, inconvenient, leak, memory, must, needed, notable, performance, prio, priority, required, risk, risky, securities, security, severity, urgent\n",
      "easy, low, medium, minor, no, non, review\n"
     ]
    }
   ],
   "source": [
    "critical = ['breaking', 'change','high', 'density', 'break', 'security', 'risk', 'risky','attention',\n",
    "            'severity', 'memory', 'leak',\"blocked\",'exclamation','failed', 'priority', 'blocker','denied',\n",
    "            'urgent','critical','important','inconvenient','broken','required','needed','confusing','failing',\n",
    "           'difficult','difficulty','hard','prio','performance',\n",
    "           \"securities\", \"incompatible\", \"hold\", \"effort\", \"followup\",\"notable\",\"must\"]\n",
    "non_critical = [\"low\",'minor','easy', 'no', 'non',\n",
    "               \"review\",'medium']\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(', '.join(sorted(critical)))\n",
    "print(', '.join(sorted(non_critical)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5ee9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "additional_set = {'due','need', 'type','cat'}\n",
    "stop_words.update(additional_set)\n",
    "stop_words.remove('no')\n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091a60f",
   "metadata": {},
   "source": [
    "## Main ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52989c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ranking_label_external.csv\", mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    ex_label_dict = {rows[0]:rows[1] for idx, rows in enumerate(reader) if idx != 0}\n",
    "    \n",
    "with open(\"ranking_label_internal.csv\", mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    in_label_dict = {rows[0]:rows[1] for idx, rows in enumerate(reader) if idx != 0}\n",
    "    \n",
    "with open(\"ranking_label_bot.csv\", mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    bot_label_dict = {rows[0]:rows[1] for idx, rows in enumerate(reader) if idx != 0}\n",
    "\n",
    "dataset = {\n",
    "    \"External\": ex_label_dict,\n",
    "    \"Internal\": in_label_dict,\n",
    "    \"Bot\": bot_label_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35d86176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2840"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = set(ex_label_dict.keys())\n",
    "all_labels.update(set(in_label_dict.keys()))\n",
    "all_labels.update(set(bot_label_dict.keys()))\n",
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d1378ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCriticalLabels(label_dict_with_counts):\n",
    "    global length_count\n",
    "    length_label_list = {}\n",
    "    critical_labels = {}\n",
    "    for label, count in label_dict_with_counts.items():\n",
    "        cleaned_label = re.sub(r'[\\(\\)\\u263a-\\U0001f645\\!]+',\"\", re.sub(r'[\\s\\:\\-/\\.]+',\" \", label)).strip().lower()\n",
    "        tokens = word_tokenize(cleaned_label)\n",
    "        filtered_words = [w for w in tokens if not w.lower() in stop_words]\n",
    "        lemmatized_output = [lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "        result = [w for w in lemmatized_output if not w.lower() in stop_words]\n",
    "        #remove digit\n",
    "        result = [x for x in result if not all(c.isdigit() for c in x)]\n",
    "        c = True if [x for x in result if x in critical] else False\n",
    "        if c:\n",
    "            if not [x for x in result if x in non_critical]:\n",
    "#                 print(label, result)\n",
    "                critical_labels[label] = count\n",
    "        \n",
    "        if len(result) not in length_count:\n",
    "            length_count[len(result)] = 0\n",
    "        length_count[len(result)] += 1\n",
    "        \n",
    "        if len(result) not in length_label_list:\n",
    "            length_label_list[len(result)] = []\n",
    "        length_label_list[len(result)].append(label)\n",
    "    return critical_labels, length_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a1c29238",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_label_dataset = {}\n",
    "length_count = {}\n",
    "length_group_list = {}\n",
    "for group, group_label_dict in dataset.items():\n",
    "    critical_label_dataset[group], length_group_list[group] = findCriticalLabels(group_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "08a21b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External\n",
      "1 669\n",
      "2 854\n",
      "3 198\n",
      "4 43\n",
      "0 10\n",
      "5 5\n",
      "6 1\n",
      "Internal\n",
      "1 767\n",
      "2 969\n",
      "3 197\n",
      "4 41\n",
      "5 8\n",
      "0 18\n",
      "Bot\n",
      "1 130\n",
      "4 12\n",
      "2 115\n",
      "3 21\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "for group, ddict in length_group_list.items():\n",
    "    print(group)\n",
    "    for le, label_list in ddict.items():\n",
    "        print(le, len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "347be5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1566, 2: 1938, 3: 416, 4: 96, 0: 29, 5: 13, 6: 1}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dd8ca8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "ex_pr_df = pd.read_csv(\"external_PR.csv\", converters={\"labels\":ast.literal_eval})\n",
    "in_pr_df = pd.read_csv(\"internal_PR.csv\", converters={\"labels\":ast.literal_eval})\n",
    "bot_pr_df = pd.read_csv(\"bot_PR.csv\", converters={\"labels\":ast.literal_eval})\n",
    "\n",
    "pr_dataset = {\n",
    "    \"External\": ex_pr_df,\n",
    "    \"Internal\": in_pr_df,\n",
    "    \"Bot\": bot_pr_df\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f2e607c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/290552 [00:00<8:26:44,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 290552/290552 [00:14<00:00, 19677.00it/s]\n",
      "  0%|          | 1/340465 [00:00<15:36:34,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340465/340465 [00:17<00:00, 19578.07it/s]\n",
      "  0%|          | 1/314274 [00:00<12:58:35,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 314274/314274 [00:16<00:00, 19591.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'External': 984, 'Internal': 2177, 'Bot': 3392}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critical_pr_count = {\n",
    "    \"External\": 0,\n",
    "    \"Internal\": 0,\n",
    "    \"Bot\": 0\n",
    "}  \n",
    "for pr_group, pr_df in pr_dataset.items():\n",
    "    print(pr_group)\n",
    "    current_group_critical_label_list = list(critical_label_dataset[pr_group].keys())\n",
    "    for _, row in tqdm(pr_df.iterrows(), total=pr_df.shape[0]):\n",
    "        isPRCritical = False\n",
    "        for la in row[\"labels\"]:\n",
    "            if la in current_group_critical_label_list:\n",
    "                isPRCritical = True\n",
    "                break\n",
    "        if isPRCritical:\n",
    "            critical_pr_count[pr_group] += 1\n",
    "#             print(row[\"labels\"])\n",
    "critical_pr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8c47a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 271\n",
      "External: 166 61.25%\n",
      "External top 5:\n",
      " {'breaking': '78', 'P3: important': '50', 'P1: urgent': '46', 'on hold': '45', '- Breaking Change': '40', 'P2: required': '40', 'Changelog/Not Needed': '34', 'Docs/Not Needed': '34', 'breaking changes': '33', 'on-hold': '25', 'P0: critical': '23', 'blocked': '19', 'ðŸ’» Change: Feature': '18', 'Change: Implementation :computer:': '18', 'security': '17', 'Tests/Not Needed': '17', 'breaking change': '16', 'priority: 4 (important)': '16', 'feedback needed': '15', 'votes needed': '15', 'severity: regression': '14', 'performance': '14', 'priority: 5 (nice to have)': '14', 'cla-not-required': '13', 'BREAKING CHANGE': '13', 'Type: Security': '13', 'xâ´ â‹… hold': '12', 'severity: 4 (inconvenient)': '12', 'severity: 3 (broken)': '12', 'oca-required': '10', 'action needed': '9', 'severity: inconvenient': '9', 'P-High': '9', 'priority: 2 (urgent)': '9', 'semver-major: breaking change': '8', 'pr: blocked': '8', 'priority: 3 (required)': '8', 'priority: high': '7', 'type: performance': '7', 'CSS:  High Density': '7', 'needs user followup': '7', '12 prio: high': '7', 'severity: 5 (confusing)': '7', 'failing build': '6', 'Breaking Change': '6', 'PR: breaking change ðŸ’¥': '6', 'difficulty:moderate': '6', 'priority / high': '6', 'important': '6', 'severity: 2 (regression)': '6', 'api break': '5', 'Critical': '5', 'Type: Breaking Change': '5', 'breaking-change': '5', 'priority: High': '5', 'change': '5', 'more info needed': '5', 'high priority': '4', 'QA NEEDED': '4', 'need changes': '4', 'Blocked': '4', 'CH: Security': '4', 'priority': '4', 'status: blocked': '4', 'ðŸ˜ˆ Breaking': '4', 'priority-1': '4', 'Breaking': '4', 'P1 - High': '4', 'change/patch': '4', 'config change': '4', 'resolution: too risky': '3', 'pr:breaking': '3', 'Status: Revision Needed': '3', 'On hold': '3', 'priority:high': '3', 'Needs author attention': '3', 'priority: enhancement': '3', 'CLA needed': '3', 'needs changes': '3', '13 prio: normal': '3', 'priority: 1 (critical)': '3', 'changes requested': '2', 'cla-required': '2', 'QA FAILED': '2', 'Type: Performance': '2', 'Awaiting Changes': '2', 'severity: memory leak': '2', 'ðŸ”¥ Important': '2', 'Meta: Denied': '2', 'PR state: needs changes': '2', 'feedback required': '2', 'release-blocker': '2', 'critical': '2', 'priority:facebook blocker': '2', 'waiting change': '2', 'prâµ ðŸ”§ performance': '2', 'difficulty: hard': '2', 'type: security': '2', 'cat/security': '2', 'changelog:1 breaking enhancement': '2', 'priority-high': '2', 'Test needed': '1', 'pr - changes requested': '1', 'prio-high': '1', 'support needed': '1', 'clarification required': '1', 'Failed UX QA': '1', 'must have': '1', 'semver-major: breaking changes': '1', 'severity: performance': '1', 'needs failing test': '1', 'Priority: High': '1', 'tests needed': '1', 'approval needed': '1', 'status/blocked': '1', 'Change: Feature :computer:': '1', 'Breaking Change :bomb:': '1', 'Investigation needed': '1', 'more information needed': '1', 'prio:urgent': '1', 'request-changes': '1', 'PR state: blocked': '1', 'awaiting-changes': '1', 'performances': '1', 'Reproduction Needed': '1', 'prio:high': '1', 'priority: p1': '1', 'priority: p0': '1', 'discuss needed': '1', 'HOLD': '1', 'Requires Further Attention': '1', 'cla-needed': '1', 'pr hold': '1', 'High': '1', 'priority/critical': '1', 'changelog:breaking-changes': '1', 'status:on-hold': '1', 'awaiting followup': '1', 'BC Break': '1', 'Status: On Hold': '1', 'Breaking changes': '1', 'waiting for changes': '1', 'feature/security': '1', 'incompatible': '1', 'Performance': '1', 'PR: Breaking Change': '1', 'failing unit tests': '1', 'Priority 1': '1', 'ci: failed': '1', 'cla needed': '1', 'update needed': '1', 'docs-required': '1', 'difficulty: very hard': '1', 'difficulty: unknown or n/a': '1', 'sÂ² ðŸ”¥ðŸ”¥ important': '1', 'test case needed': '1', 'Priority: 3 - High': '1', ':exclamation: DO NOT MERGE :exclamation:': '1', 'needs-priority': '1', 'P-Critical': '1', 'C-High': '1', 'regression test needed': '1', 'prio:normal': '1', 'pÂ¹ ðŸ”¥ðŸ”¥ðŸ”¥ critical': '1', 'flag: Performance': '1', 'Information needed': '1'}\n",
      "Internal: 205 75.65%\n",
      "Internal top 5:\n",
      " {'breaking': '311', 'breaking change': '141', 'P2: required': '104', 'change/patch': '96', 'performance': '80', 'priority/high': '74', 'release-blocker': '72', 'P1: urgent': '66', 'P3: important': '60', 'Tests/Not Needed': '58'}\n",
      "Bot: 26 9.59%\n",
      "Bot top 5:\n",
      " {'security': '3248', 'breaking': '28', 'CH: Security': '23', 'Type: Security': '21', 'Security': '11', 'blocked': '10', 'needs changes': '9', 'cat/security': '7', 'security fix': '6', 'on hold': '6'}\n"
     ]
    }
   ],
   "source": [
    "all_critical_labels = None\n",
    "for _, label_d in critical_label_dataset.items():\n",
    "    if not all_critical_labels:\n",
    "        all_critical_labels = set(label_d.keys())\n",
    "    else:\n",
    "        all_critical_labels.update(set(label_d.keys()))\n",
    "\n",
    "all_count = len(all_critical_labels)\n",
    "print(\"All:\", all_count)\n",
    "ex_count = len(critical_label_dataset[\"External\"])\n",
    "ex_top5 = dict(sorted(critical_label_dataset[\"External\"].items(), key=lambda item: int(item[1]), reverse=True))\n",
    "print(\"External: {} {:.2f}%\".format(ex_count, ex_count/all_count*100))\n",
    "print(\"External top 5:\\n\",ex_top5)\n",
    "\n",
    "in_count = len(critical_label_dataset[\"Internal\"])\n",
    "in_top5 = dict(sorted(critical_label_dataset[\"Internal\"].items(), key=lambda item: int(item[1]), reverse=True)[:10])\n",
    "print(\"Internal: {} {:.2f}%\".format(in_count, in_count/all_count*100))\n",
    "print(\"Internal top 5:\\n\",in_top5)\n",
    "\n",
    "bot_count = len(critical_label_dataset[\"Bot\"])\n",
    "bot_top5 = dict(sorted(critical_label_dataset[\"Bot\"].items(), key=lambda item: int(item[1]), reverse=True)[:10])\n",
    "print(\"Bot: {} {:.2f}%\".format(bot_count, bot_count/all_count*100))\n",
    "print(\"Bot top 5:\\n\",bot_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "42be0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('attention_label_ranking.json', 'w') as outfile:\n",
    "     json.dump(critical_label_dataset, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
